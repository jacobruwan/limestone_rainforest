---
title: "model_development"
output: html_document
---

```{r}
# define the vector of possible predictors, exclude random effects
response <- "sla_ca_mean"
temp_predictors <- names(sla_com.df)[-(which(names(sla_com.df) %in% c("sla_ca_mean", "sla_ca_sd","site", "site_trans","transect", "quadrat",
                                                         "min_temp", "range_temp",
                                                         "overall_seedling_cover", "scaled_overall_seedling_cover",
                                                         "total_dom_abundance", "scaled_total_dom_abundance")))]

# Remove all leaf data
# interactions <- c("site:dom_species_id", "site:av_quad_gft", "site:av_quad_compaction",
#          "dom_species_id:scaled_av_trans_elevation", "dom_species_id:av_quad_gft", "dom_species_id:av_quad_compaction")

predictors <- c(temp_predictors, paste0(temp_predictors, " + ", temp_predictors, ":site"))
# predictors <- c(temp_predictors, interactions)

# Iterate through code that creates all possible combinations of predictors: 7 predictors means 7^2 combinations
possible_predictor_combinations <- list()
index <- 1

for (i in 1:length(predictors)) {
  for (j in i:length(predictors)) {
  possible_predictor_combinations[[index]] <- i:j
  index <- index + 1
  }
}

# Create formula's
formula_string_combinations <- list()

for (i in 1:length(possible_predictor_combinations)) {

  formula_string_combinations[[i]] <- predictors[possible_predictor_combinations[[i]][1]]

  if (length(possible_predictor_combinations[[i]]) > 1) {
    for (j in 2:length(possible_predictor_combinations[[i]])) {
      formula_string_combinations[[i]] <- paste(formula_string_combinations[[i]],
                                                predictors[possible_predictor_combinations[[i]][j]],
                                                sep = " + ")
    }
  }

}

# Find the full formula of predictors for INLA step
length_formulastring <- data.frame(Index=NA, Length=NA)

for (i in 1:length(formula_string_combinations)) {
  length_formulastring[i,1] <- i
  length_formulastring[i,2] <- nchar(formula_string_combinations[[i]])
}

full_formula <- length_formulastring %>% 
  arrange(desc(Length)) %>%
  head(1) %>%
  select(Length) %>%
  unlist(use.names = FALSE)
```




<!-- #### Ruwans Stepwise for Aggregate -->
<!-- ```{r} -->
<!-- # Run all possible INLA models -->
<!-- loglinear_stepwise_summary <- data.frame(Formula = "-", Log_Likelihood = NA) -->

<!-- # In for loop, run the model and combine the log likelihood estimate into a data.frame -->
<!-- for (i in 1:length(formula_string_combinations)) { -->
<!-- inla_formula <- as.formula(paste0("log(sla_ca_mean) ~ site + ", -->
<!--                           formula_string_combinations[[i]], -->
<!--                           " + f(site_trans, model='iid') + f(quadrat:site_trans, model = 'iid')")) -->

<!-- fit <- inla(inla_formula, -->
<!--             family = "gaussian", -->
<!--             data = sla_com.df) -->

<!-- loglinear_stepwise_summary <- loglinear_stepwise_summary %>% -->
<!--   rbind(data.frame(Formula = formula_string_combinations[[i]], -->
<!--                    Log_Likelihood = summary(fit)[["mlik"]][2])) -->
<!-- print(i) -->
<!-- } -->

<!-- save(loglinear_stepwise_summary, file = paste0(data_folder, "loglinear_stepwise_summary.RData")) -->

<!-- # load(paste0(dropbox, "loglinear_stepwise_summary.RData")) -->
<!-- # -->
<!-- # top10 <- loglinear_stepwise_summary %>% -->
<!-- #   arrange(desc(Log_Likelihood)) %>% -->
<!-- #   head(10) -->
<!-- # -->
<!-- # top10 -->
<!-- ``` -->

<!-- ```{r} -->

<!-- load(paste0(data_folder, "loglinear_stepwise_summary.RData")) -->

<!-- loglinear_stepwise_summary %>% -->
<!--   arrange(desc(Log_Likelihood)) %>% -->
<!--   head(10) -->
<!-- # fit <- -->

<!-- ``` -->

##### Final Model
```{r}
# RUn a model on the top 3 variables identified
inla_formula <- as.formula("log(sla_ca_mean) ~  site + scaled_overall_seedling_cover + f(site_trans, model='iid')")

 # 

fit <- inla(inla_formula,
            family = "gaussian",
            data = sla_com.df,
            control.compute =list(dic=TRUE, waic= TRUE, cpo = TRUE, 
                                  mlik = TRUE,config=TRUE),
            control.predictor=list(compute=T))

# analyse the output of the model
# summary(fit)
```

The final model regresses the log of community aggregated SLA by site and overall seedling cover. This results is determined by the maximum marginal log-Likelihood and by observing the credible intervals. As this model only has 30 observations and there are 30 unique quadrats, the only random effect variable included is the variation between transects.

<!-- $$ -->
<!-- log(SLA_{Community Aggregated}) = \beta_0 + \beta_{Pristine} + \beta_{Overall Seedling Cover} + \epsilon_{transect} +\epsilon_{residual} -->

<!-- $$ -->


<!-- ##### Frequentist -->
<!-- ```{r} -->
<!-- fit2 <- lmer(log(sla_ca_mean) ~ site + overall_seedling_cover + (1|site_trans), -->
<!--              data = sla_com.df) -->

<!-- summary(fit2) -->
<!-- ``` -->



##### Model Fit

The figure below highlights the fitted predictions of the model against the observed values, the standardised residuals are shown on the right. These residual plot shows that there ihe residuals are more likely to be positive in the middle range of fitted values, which is not ideal. However, there are no large concerns for the model fit, as the sample size is low.

```{r, fig.width = 5}
# summary(fit)
predictions <- fit$summary.fitted.values$mean
dataset <- sla_com.df

pred.df <- dataset %>% 
      mutate(fitted = predictions,
             observed = log(sla_ca_mean),
             residuals = observed - fitted,
             std_residuals = (residuals - mean(residuals))/sqrt(var(residuals)),
             cpo = fit$cpo$pit)

## Fitted vs Predicted
fit_vs_pred <- pred.df %>%
  ggplot(aes(x = observed, y = fitted)) +
  geom_point() +
  xlab("Observed Mean SLA (CA)") +
  ylab("Fitted Values") +
  theme_project() +
  coord_equal() +
  geom_abline() +
  ggtitle("Observed vs Fitted SLA")

## Fitted vs Standardised Residuals
fit_vs_res <- pred.df %>%
  ggplot(aes(x = fitted, y = std_residuals)) +
  geom_point() +
  xlab("Fitted Values") +
  ylab("Standardised Residuals") +
  theme_project() +
  geom_abline(slope = 0)+
  geom_abline(slope = 0, intercept = 1.5)+
  geom_abline(slope = 0, intercept = -1.5) +
  ggtitle("Standardised Residuals")

multiplot(fit_vs_pred, fit_vs_res,
          layout = matrix(c(1,2), nrow = 1))


 # Histogram of predictions
hist_res <- pred.df %>%
  ggplot(aes(x = fitted)) +
  geom_histogram(bins=7) +
  theme_project() +
  ggtitle("Histograms of Fitted Values")
  

# CPO Values: QQ plot and Histogram
hist_cpo <- pred.df %>%
  ggplot(aes(x = cpo)) +
  geom_histogram(bins=7) +
  theme_project() +
  ggtitle("Histograms of CPO")
```

The model fit is further investigated in the code below, QQ plots and histograms of residual and CPO values. The CPO QQ plot demonstrate a good fit for the middles values of the QQ line, with deviations at the tail end. This is supported by the histogram, suggesting there are no major concerns for model fit. The residual qq plots and histogram support the trend shown in the figure above, where there isn't an even distribution around the zero line. However, there are no dramatic deviations, thus the model is considered appropriate.

```{r, fig.height = 5, fig.width = 7}
par(mfrow = c(2,2))
# CPI QQ plot
qqnorm(pred.df$cpo)
qqline(pred.df$cpo)
title("CPO                                         ")

CPO <- pred.df$cpo
hist(CPO)

# Residuals QQ plot
qqnorm(pred.df$residuals)
qqline(pred.df$residuals)
title("Residuals                                                   ")

Residuals <- pred.df$residuals
hist(Residuals)

par(mfrow = c(1,1))
```

##### Fixed Effect Credible Intervals
In the figure below, the credible intervals of each estimated paramater is shown, transformed from the log scale to the original SLA domain. This graph demonstrates that a unit increase in the scaled overall seedling cover can increase community agrgegated SLA from a value between 0.4 up to 1.1, keeping all else constant. This presents some uncertainty, however it is clear that overall seedling cover has a positive relationship as the credible interval does not include zero. Similarly, given the same overall seedling cover, a pristine forest areas is expected to have a positive increase on community aggregated sla value. This increase can range between 1.1 and 2.5 based on the credible intervals estimated.

```{r }
## How to look at predictions and compare to original???
fixed <- summary(fit)$fixed
vec <- fixed[1:length(fixed)]
# random <- summary(fit)$random
n <- length(summary(fit)$fixed)
n1 <- n/7

# Collect and plot the intercals
# How to standardise the intervals?
# Standardise the response variable?
fixed.df <- data.frame(Estimate = row.names(fixed),
           Mean = vec[1:n1],
           SD = vec[(n1+1):(2*n1)],
           quant0.025 = vec[(2*n1+1):(3*n1)],
           quant0.5 = vec[(3*n1+1):(4*n1)],
           quant0.975 = vec[(4*n1+1):(5*n1)],
           mode = vec[(5*n1+1):(6*n1)]) %>%
  mutate(Estimate = factor(Estimate, levels = row.names(fixed)[n1:1], ordered = TRUE)) %>%
  tbl_df() %>%
  mutate(beta = 0:(n1-1)) %>%
  mutate(Est2 = paste0(Estimate, " - b", beta),
         Est2 = reorder(Est2, rev(beta))) %>%
  mutate(RR_lower = exp(quant0.025)-1, RR_upper = exp(quant0.975)-1)

fixed.df %>%
  ggplot(aes(y = Est2, x = exp(quant0.5), xmin = exp(quant0.025), xmax = exp(quant0.975))) +
  geom_errorbarh() +
  theme_project() +
  ggtitle("SLA Agg - Fixed Effects") +
  xlab("Credible Intervals") +
  ylab("Parameter") +
  geom_vline(xintercept = 0) +
  scale_x_continuous(breaks = seq(0, 90, 3))


# ggsave(paste0(data_folder, "sla_", "agg","_estimates.png"), width = 3, height = 1.5, dpi = 900)
```

##### Random Effect Credible Intervals
Based on the INLA model, no variation was attributed to between transects. This is a surprising result, as the exploratory analysis demonstrate distinct differences in log SLA between transects.

```{r}
## How to look at predictions and compare to original???
random <- summary(fit)$hyperpar
# random

randomeffects <- data.frame(hyperparameter = c("Residual", "Transect"),# "Quadrat:Transect"),
           precision = random[[1]],
           lb = random[[3]],
           ub = random[[5]]) %>%
  mutate(variance = 1/precision,
         varlb = 1/lb,
         varub = 1/ub) %>%
  mutate(totalvar = sum(variance),
         totallb = sum(varlb),
         totalub = sum(varub)) %>%
  mutate(explained = variance/totalvar,
         explainedlb = varlb/totallb,
         explainedub = varub/totalub) %>%
  arrange(desc(explained))

# 
randomeffects %>%
  ggplot(aes(y = hyperparameter, x = variance, xmin = varlb, xmax = varub)) +
  geom_errorbarh() +
  theme_project() +
  ggtitle("SLA Agg - Random Effects") +
  xlab("Credible Interval") +
  ylab("Hyperparameter")

randomeffects %>%
  mutate(`Variation Explained` = percent(explained)) %>%
  select(hyperparameter, `Variation Explained`)

# ggsave(paste0(data_folder, "sla_", "agg","_randomeff.png"), width = 3.5, height = 1.8, dpi = 900)

```


