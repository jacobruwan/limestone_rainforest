---
title: "model_development"
output: html_document
---

```{r}
datafolder <- "C:\\Users\\Jacob\\Dropbox\\Semester 2 2017\\MXB344\\Project\\Data\\"

load(paste0(datafolder, "domseedlingcover_rq1.RData"))
```


#### Final Model
```{r}

fit3 = inla(r ~ dom_species_id + dom_abundance 
            + f(site_trans, model="iid") +  f(quadrat:site_trans, model = "iid"),
            family="gaussian",
            data=domseedlingcover, control.compute = list(dic=TRUE, waic = TRUE, cpo=TRUE,
                                                          mlik = TRUE, config=TRUE),
            control.predictor = list(compute=T))
# summary(fit3)

```


From this regression, it appears that the significant variables in this model are species id and species abundance. Each dominant species has a unique effect on the seedling cover. The abundance of the dominant species has a positive effect on the seedling cover


#### Model Fit
In the figure below, it can be noted that there is some issues with fitted values that extend higher than -1. As fitted values increase, the variation of standardised residuals starts to decrease. This would imply that for larger fitted values, the model is not suffice. 

```{r, fig.width = 5}
# summary(fit)
fit <- fit3

predictions <- fit$summary.fitted.values$mean
dataset <- domseedlingcover

pred.df <- dataset %>% 
      mutate(fitted = predictions,
             observed = r,
             residuals = observed - fitted,
             std_residuals = (residuals - mean(residuals))/sqrt(var(residuals)),
             cpo = fit$cpo$pit)

## Fitted vs Predicted
fit_vs_pred <- pred.df %>%
  ggplot(aes(x = observed, y = fitted)) +
  geom_point() +
  xlab("Observed Mean SLA (CA)") +
  ylab("Fitted Values") +
  theme_project() +
  coord_equal() +
  geom_abline() +
  ggtitle("Observed vs Fitted SLA")

## Fitted vs Standardised Residuals
fit_vs_res <- pred.df %>%
  ggplot(aes(x = fitted, y = std_residuals)) +
  geom_point() +
  xlab("Fitted Values") +
  ylab("Standardised Residuals") +
  theme_project() +
  geom_abline(slope = 0)+
  geom_abline(slope = 0, intercept = 1.5)+
  geom_abline(slope = 0, intercept = -1.5) +
  ggtitle("Standardised Residuals")

multiplot(fit_vs_pred, fit_vs_res,
          layout = matrix(c(1,2), nrow = 1))


 # Histogram of predictions
hist_res <- pred.df %>%
  ggplot(aes(x = fitted)) +
  geom_histogram(bins=7) +
  theme_project() +
  ggtitle("Histograms of Fitted Values")
  

# CPO Values: QQ plot and Histogram
hist_cpo <- pred.df %>%
  ggplot(aes(x = cpo)) +
  geom_histogram(bins=7) +
  theme_project() +
  ggtitle("Histograms of CPO")
```

However, inspecting the QQ plot in the figure below, it appears that the data fits fairly well with the model. This deduction is rather conflicting with the previous graph, hence a third graph was investigated. The histogram of residuals vaguely resembles a normal distribution curve, which therefore implies that the model fits well to the data. As two graphs corroborate eachother, it is concluded that the model was a good fit for the model. 

```{r, fig.height = 5, fig.width = 7}
par(mfrow = c(2,2))
# CPI QQ plot
qqnorm(pred.df$cpo)
qqline(pred.df$cpo)
title("CPO                                         ")

CPO <- pred.df$cpo
hist(CPO)

# Residuals QQ plot
qqnorm(pred.df$residuals)
qqline(pred.df$residuals)
title("Residuals                                                   ")

Residuals <- pred.df$residuals
hist(Residuals)

par(mfrow = c(1,1))
```

#### Fixed Effect Credible Intervals
In this model, it is clear that all the variables are significant. This is because no variables' credible interval overlaps '0'. The credible interval for abundance shows that a unit increase in (scaled) abundance can increase (transformed) seedling cover by 0.59 to 1.11.

```{r }
## How to look at predictions and compare to original???
fixed <- summary(fit3)$fixed
vec <- fixed[1:length(fixed)]
# random <- summary(fit)$random
n <- length(summary(fit3)$fixed)
n1 <- n/7
# Collect and plot the intercals
# How to standardise the intervals?
# Standardise the response variable?
fixed.df <- data.frame(Estimate = row.names(fixed),
Mean = vec[1:n1],
SD = vec[(n1+1):(2*n1)],
quant0.025 = vec[(2*n1+1):(3*n1)],
quant0.5 = vec[(3*n1+1):(4*n1)],
quant0.975 = vec[(4*n1+1):(5*n1)],
mode = vec[(5*n1+1):(6*n1)]) %>%
mutate(Estimate = factor(Estimate, levels = row.names(fixed)[n1:1], ordered = TRUE)) %>%
mutate(beta = 0:(n1-1)) %>%
mutate(Est2 = paste0(Estimate, " - b", beta),
Est2 = reorder(Est2, rev(beta)))
fixed.df %>%
ggplot(aes(y = Est2, x = quant0.5, xmin = quant0.025, xmax = quant0.975)) +
geom_errorbarh() +
theme_project() +
ggtitle("Standardised Predictors") +
xlab("Credible Intervals") +
ylab("Parameter") +
geom_vline(xintercept = 0)
```



#### Variation Breakdown
```{r}
## How to look at predictions and compare to original???
random <- summary(fit3)$hyperpar
# random
randomeffects <- data.frame(hyperparameter = c("Residual", "Transect", "Quadrat:Transect"),
precision = random[[1]],
lb = random[[3]],
ub = random[[5]]) %>%
mutate(variance = 1/precision,
varlb = 1/lb,
varub = 1/ub) %>%
mutate(totalvar = sum(variance),
totallb = sum(varlb),
totalub = sum(varub)) %>%
mutate(explained = variance/totalvar,
explainedlb = varlb/totallb,
explainedub = varub/totalub) %>%
arrange(desc(explained))
# 
randomeffects %>%
ggplot(aes(y = hyperparameter, x = variance, xmin = varlb, xmax = varub)) +
geom_errorbarh() +
theme_project() +
ggtitle("Hyperparameters") +
xlab("Credible Interval") +
ylab("Hyperparameter")
randomeffects %>%
mutate(`Variation Explained` = percent(explained)) %>%
select(hyperparameter, `Variation Explained`)


```

From the graph and table above, the random effects account for 0% of the variation, where as the fixed effects account for 100% of the variation. This would imply that a fixed effects model should be suffice for this analysis. 

